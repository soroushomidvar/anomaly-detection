{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Imports and Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pyspark.sql.functions import col\n",
    "from functools import reduce\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "from pyspark.sql.functions import col, split, size, isnan, array_contains, array_min, when, count\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, StringType, FloatType\n",
    "import pyspark.sql.functions as f\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import pathlib\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import statistics\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "DATASET_PATH = '/Users/Soroush/Desktop/Thesis/Code/Datasets/Smart*/apartment/'\n",
    "\n",
    "# BASE_PATH=pathlib.Path().absolute()\n",
    "# KMEANS_REL_PATH=\"kmeans models\"\n",
    "# DATASET_REL_PATH=\"dataset\"\n",
    "# DATASET_PATH=os.path.join(BASE_PATH,DATASET_REL_PATH)\n",
    "# KMEANS_PATH=os.path.join(BASE_PATH,KMEANS_REL_PATH)\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_DRIVER_PYTHON=python3.6\n",
      "env: PYSPARK_PYTHON=python3.6\n",
      "env: ARROW_PRE_0_15_IPC_FORMAT=1\n"
     ]
    }
   ],
   "source": [
    "# env variables\n",
    "if platform.system() == 'Windows':\n",
    "    %env PYSPARK_DRIVER_PYTHON = python\n",
    "    %env PYSPARK_PYTHON = python\n",
    "elif platform.system() == 'Linux':\n",
    "    %env PYSPARK_DRIVER_PYTHON = python\n",
    "    %env PYSPARK_PYTHON = python3\n",
    "else:\n",
    "    %env PYSPARK_DRIVER_PYTHON = python3.6\n",
    "    %env PYSPARK_PYTHON = python3.6\n",
    "\n",
    "# incompatibility with Pyarrow\n",
    "# need to install Pyarrow 0.14.1 or lower or Set the environment variable ARROW_PRE_0_15_IPC_FORMAT=1\n",
    "%env ARROW_PRE_0_15_IPC_FORMAT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and save .read_pickle() and .to_pickle()\n",
    "\n",
    "# save\n",
    "# dataset.to_pickle(DATASET_PATH+\"dataset.pkl\")\n",
    "# aggregated_dataset.to_pickle(DATASET_PATH+\"aggregated_dataset.pkl\")\n",
    "# json_dataset.to_pickle(DATASET_PATH+\"json_dataset.pkl\")\n",
    "# dataset.to_csv(DATASET_PATH+\"dataset.csv\")\n",
    "# aggregated_dataset.to_csv(DATASET_PATH+\"aggregated_dataset.csv\")\n",
    "# json_dataset.to_csv(DATASET_PATH+\"json_dataset.csv\")\n",
    "# aggregated_dataset_rowBased.to_csv(DATASET_PATH+\"aggregated_dataset_rowBased.csv\")\n",
    "\n",
    "\n",
    "# load\n",
    "# dataset=pd.read_pickle(DATASET_PATH+\"dataset.pkl\")\n",
    "# aggregated_dataset=pd.read_pickle(DATASET_PATH+\"aggregated_dataset.pkl\")\n",
    "# json_dataset=pd.read_pickle(DATASET_PATH+\"json_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create appropriate dataset\n",
    "\n",
    "# dataset address: http://traces.cs.umass.edu/index.php/Smart/Smart\n",
    "\n",
    "# Extract File\n",
    "# import tarfile\n",
    "# !tar -xf '/gdrive/My Drive/a.gzip' -C '/gdrive/My Drive/'\n",
    "\n",
    "# load\n",
    "\n",
    "\n",
    "def load_smart_star_dataset(dataset_path):\n",
    "\n",
    "    # length of file path\n",
    "    LENGTH = len(dataset_path)+5  # (5 for removing 2014/, 2015/ and 2016/)\n",
    "\n",
    "    df_merged = pd.DataFrame(columns=['date'])\n",
    "\n",
    "    # 2014\n",
    "    #path_2014 = r'/gdrive/My Drive/Dataset/apartment/2014'\n",
    "    path_2014 = dataset_path+'2014'\n",
    "    all_2014_paths = glob.glob(path_2014 + \"/Apt*.csv\")\n",
    "    df_merged_2014 = pd.DataFrame(columns=['date'])\n",
    "    for file_name in all_2014_paths:\n",
    "        column_name = file_name[LENGTH:-4]  # (4 for .csv)\n",
    "        # column_name = file_name.replace(\"dataset/2014/\", \"\").replace(\"_2014.csv\",\"\")\n",
    "        df = pd.read_csv(file_name, names=[\"date\", column_name])\n",
    "        df_merged_2014 = pd.merge(\n",
    "            df_merged_2014, df, on='date', how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    # 2015\n",
    "    df_merged_2015 = pd.DataFrame(columns=['date'])\n",
    "    #path_2015 = r'/gdrive/My Drive/Dataset/apartment/2015'\n",
    "    path_2015 = dataset_path+'2015'\n",
    "    all_2015_paths = glob.glob(path_2015 + \"/Apt*.csv\")\n",
    "    for file_name in all_2015_paths:\n",
    "        column_name = file_name[LENGTH:-4]\n",
    "        # column_name = file_name.replace(\"dataset/2015/\", \"\").replace(\"_2015.csv\",\"\")\n",
    "        df = pd.read_csv(file_name, names=[\"date\", column_name])\n",
    "        df_merged_2015 = pd.merge(\n",
    "            df_merged_2015, df, on='date', how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    # 2016\n",
    "    df_merged_2016 = pd.DataFrame(columns=['date'])\n",
    "    #path_2016 = r'/gdrive/My Drive/Dataset/apartment/2016'\n",
    "    path_2016 = dataset_path+'2016'\n",
    "    all_2016_paths = glob.glob(path_2016 + \"/Apt*.csv\")\n",
    "    for file_name in all_2016_paths:\n",
    "        column_name = file_name[LENGTH:-4]\n",
    "        # column_name = file_name.replace(\"dataset/2016/\", \"\").replace(\"_2016.csv\",\"\")\n",
    "        df = pd.read_csv(file_name, names=[\"date\", column_name])\n",
    "        df_merged_2016 = pd.merge(\n",
    "            df_merged_2016, df, on='date', how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    # merge all years\n",
    "    df_merged = df_merged_2014.append(df_merged_2015, ignore_index=True).append(\n",
    "        df_merged_2016, ignore_index=True)\n",
    "    final = df_merged\n",
    "    # save\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data\n",
    "def agg_by_date(final):\n",
    "    final['date'] = pd.to_datetime(final['date'],)\n",
    "    final.index = final['date']\n",
    "\n",
    "    # for more than to NaN : .apply(lambda x: x.sum() if x.isnull().sum() <= 2 else np.nan)\n",
    "    final_agg_by_hour = final.resample('60T').mean()\n",
    "\n",
    "    final = final_agg_by_hour.resample('D').aggregate(\n",
    "        lambda x: x.tolist())  # for tuple: .aggregate(lambda x: tuple(x))\n",
    "\n",
    "    # remove first and last row\n",
    "    # aggregated_dataset.drop(pd.to_datetime('2016-12-28'),inplace=True)\n",
    "    # aggregated_dataset.drop(pd.to_datetime('2014-10-15'),inplace=True)\n",
    "    # final=final.iloc[1:-1]\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column_based df to row_based\n",
    "def col_to_row(df):\n",
    "    # house_id=df.columns\n",
    "    df.reset_index(inplace=True)\n",
    "    return pd.melt(df, id_vars=['date'], value_name='power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = load_smart_star_dataset(DATASET_PATH)\n",
    "\n",
    "# aggregate by date\n",
    "aggregated_dataset = agg_by_date(dataset)\n",
    "\n",
    "# aggregate by date, row-based\n",
    "aggregated_dataset_rowBased = col_to_row(aggregated_dataset)\n",
    "aggregated_dataset_rowBased.sort_values(\n",
    "    ['date', 'variable'], ascending=[True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dataset.to_csv(DATASET_PATH+\"dataset.csv\")\n",
    "aggregated_dataset.to_csv(DATASET_PATH+\"aggregated_dataset.csv\")\n",
    "aggregated_dataset_rowBased.to_csv(\n",
    "    DATASET_PATH+\"aggregated_dataset_rowBased.csv\")\n",
    "\n",
    "dataset.to_pickle(DATASET_PATH+\"dataset.pkl\")\n",
    "aggregated_dataset.to_pickle(DATASET_PATH+\"aggregated_dataset.pkl\")\n",
    "aggregated_dataset_rowBased.to_pickle(\n",
    "    DATASET_PATH+\"aggregated_dataset_rowBased.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
